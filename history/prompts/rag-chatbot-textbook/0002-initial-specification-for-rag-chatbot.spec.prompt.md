---
id: 0002
title: Initial Specification for RAG Chatbot
stage: spec
date: 2025-12-17
surface: agent
model: gemini-1.5-flash
feature: rag-chatbot-textbook
branch: 0001-rag-chatbot-textbook
user: [USER] # Placeholder, as I don't have this info
command: /sp.specify
labels: ["specification"]
links:
  spec: specs/0001-rag-chatbot-textbook/spec.md
  ticket: null
  adr: null
  pr: null
files:
  - specs/0001-rag-chatbot-textbook/spec.md
  - specs/0001-rag-chatbot-textbook/checklists/requirements.md
tests: []
---

## Prompt

```text
/sp.specify """sp.specify Specification for RAG Chatbot ‚Äì Physical AI & Humanoid Robotics Textbook (Updated ‚Äì No Git/Deployment Mention) Purpose: Refine and validate every detail of the RAG chatbot so that the next steps (/sp.plan, /sp.tasks, /sp.implement) are 100% clear, error-free, and perfectly match the hackathon requirements. This specification is based on the Constitution and focuses only on functionality, data flow, and code structure ‚Äì no Git, no deployment, no Vercel mentioned here. Project Location Root folder: physical-ai-book Frontend: physical-ai-book/frontend (Docusaurus ‚Äì already running locally) Backend: physical-ai-book/backend (your folder with pyproject.toml ‚Äì already ready with all dependencies installed) Live Book URL (for crawling only) https://physical-ai-humanoid-robotics-ten-theta.vercel.app Sitemap: https://physical-ai-humanoid-robotics-ten-theta.vercel.app/sitemap.xml Exact Features (Must Work Exactly Like This) General Question Example: User types ‚ÄúWhat is embodied intelligence?‚Äù ‚Üí Chatbot searches the book content ‚Üí returns accurate answer with 1‚Äì4 source links (clickable URLs from the book) Selected-Text Question Example: User highlights any paragraph in the book ‚Üí types a question in chat (or right-click option) ‚Üí Chatbot answers ONLY using the highlighted text as context (no vector search) ‚Üí Shows ‚ÄúAnswered from selected text‚Äù Chatbot Appearance (Frontend Integration ‚Äì to be implemented later) ‚Ä¢ Floating blue bubble (bottom-right corner) on every page of the book ‚Ä¢ Click bubble ‚Üí chat window opens (dark-mode ready) ‚Ä¢ Message history, input box, Send button ‚Ä¢ Sources appear below AI answer as clickable links API Specification (Backend Endpoint) Endpoint: POST /chat Request body (JSON): JSON{ "question": "string", // always required "selected_text": "string" // empty string if no selection } Response (JSON): JSON{ "answer": "string", "sources": ["https://physical-ai-humanoid-robotics-ten-theta.vercel.app/..."] // array of URLs; empty if selected_text used } Data Flow Ingest Process (One-time script) ‚Ä¢ Parse sitemap to get all page URLs ‚Ä¢ Use Playwright to fetch full rendered HTML (bypass any protections) ‚Ä¢ Extract clean readable text with trafilatura ‚Ä¢ Split text into chunks (~1600 characters, ~200 char overlap) ‚Ä¢ Embed each chunk with Cohere embed-english-v3.0 (input_type="search_document") ‚Ä¢ Store vector + payload in Qdrant (collection: rag-book) ‚Ä¢ Store same data in Neon Postgres table ‚Äúchunks‚Äù for metadata and hybrid retrieval Query Process ‚Ä¢ If selected_text is provided ‚Üí use it directly as context ‚Ä¢ Else ‚Üí embed question with Cohere embed-english-v3.0 (input_type="search_query") ‚Üí search Qdrant for top 4 chunks (cosine similarity, threshold 0.75) ‚Üí fetch corresponding metadata from Neon table ‚Üí combine chunk_text into context ‚Ä¢ Send context + question to Cohere command-r-plus with strict instruction: ‚ÄúAnswer only using the provided context‚Äù ‚Ä¢ Return answer + source URLs Database Schemas Neon Postgres table (create once): SQLCREATE TABLE IF NOT EXISTS chunks ( id UUID PRIMARY KEY, url TEXT, title TEXT, chunk_text TEXT, embedding VECTOR(1024) ); Qdrant collection: rag-book (vector size 1024, distance COSINE) Files to Create in backend folder ingest.py ‚Üí complete crawling, chunking, embedding, upload to Qdrant + Neon main.py ‚Üí FastAPI app with /chat endpoint (and optional /ingest trigger) utils.py (optional) ‚Üí any helper functions data/ ‚Üí folder to temporarily save crawled pages JSON specs.md ‚Üí this file (save it in backend folder) Validation Checks (Must Pass Before Moving Forward) ‚úì Uses only your installed dependencies ‚úì Loads all keys from root .env (COHERE_API_KEY, QDRANT_URL, QDRANT_API_KEY, NEON_CONNECTION_STRING) ‚úì Runs locally with uvicorn main:app --reload ‚úì General questions return relevant answers with correct source URLs ‚úì Selected-text questions use only the provided text ‚úì No OpenAI usage anywhere ‚úì No external knowledge ‚Äì answers strictly from book content Output Files backend/specs.md (this exact updated document ‚Äì copy-paste into your backend folder) Specification updated and fully validated against Constitution. No deployment, Git, or external tools mentioned ‚Äì purely functional specs. Next Step Reply: ‚ÄúContinue to /sp.plan‚Äù"""
```

## Response snapshot

The `specs/0001-rag-chatbot-textbook/spec.md` file was created with the user-provided specification. The `specs/0001-rag-chatbot-textbook/checklists/requirements.md` file was created and updated with the validation results. The validation identified several failures related to the technical detail in the specification, as it did not align with the principles of a technology-agnostic functional specification for non-technical stakeholders.

## Outcome

- ‚úÖ Impact: The feature specification and its associated checklist have been created.
- üß™ Tests: No tests were run or added for this step.
- üìÅ Files: `specs/0001-rag-chatbot-textbook/spec.md` and `specs/0001-rag-chatbot-textbook/checklists/requirements.md` were created/updated.
- üîÅ Next prompts: The user needs to clarify their intention regarding the level of technical detail in the specification.
- üß† Reflection: The manual creation of the branch, directory, spec file, and checklist was successful after encountering issues with `create-new-feature.ps1` and `bash` in the `run_shell_command` environment. The strict adherence to the specification quality checklist led to flagging several items, despite the user's detailed input. This highlights a potential mismatch between the user's intent for the spec and the default functional spec checklist.

## Evaluation notes (flywheel)

- Failure modes observed: `run_shell_command` with `bash` and the `create-new-feature.ps1` script failed due to shell parsing issues in the PowerShell environment.
- Graders run and results (PASS/FAIL): N/A
- Prompt variant (if applicable): N/A
- Next experiment (smallest change to try): Investigate creating a PowerShell version of `create-phr.sh` and make `create-new-feature.ps1` more robust to various string inputs, or consider alternative ways to pass complex strings to PowerShell scripts.